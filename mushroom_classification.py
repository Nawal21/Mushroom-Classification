# -*- coding: utf-8 -*-
"""Mushroom_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H6izdIDNC1lWUNrVJbQDQKqWvhRl458j
"""

import pandas as pd
import numpy as np

dlab = pd.read_csv('mushroom edibility classification dataset.csv')
dlab.tail()

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

dlab.shape

dlab.isnull().sum()

dlab = dlab.drop(['Unnamed: 0'], axis = 1)
dlab.shape

dlab.tail()

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(dlab[ ['cap-shape'] ])
impute.fit(dlab[ ['cap-color'] ])
dlab['cap-shape'] = impute.transform(dlab[ ['cap-shape'] ])
dlab['cap-color'] = impute.transform(dlab[ ['cap-color'] ])

dlab.tail()

dlab.isnull().sum()

dlab.info()

dlab['bruises'] = dlab.bruises.map({'no bruises': 0, 'bruises is there' : 1})
dlab.tail()

dlab['class'].unique()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
dlab['class'] = encoder.fit_transform(dlab['class'])
print(dlab['class'])

y = dlab['class']
X = dlab.drop(columns='class')

dlab

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

mdl = LogisticRegression()
mdl.fit(X_train, y_train)
predictions = mdl.predict(X_test)
print(predictions)

result_1 = accuracy_score(y_test, predictions)
print (result_1)

dlab

dlab['class'].unique

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

clsf = DecisionTreeClassifier(criterion='entropy',random_state=1)
clsf.fit(X_train,y_train)
y_pred = clsf.predict(X_test)
print(y_pred)

result=accuracy_score(y_test,y_pred)
print(result)

from sklearn import tree
import matplotlib.pyplot as plt

fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=150)
tree.plot_tree(clsf,
               feature_names = X.columns, 
               class_names=['1','0'],
               filled = True);

import matplotlib.pyplot as ppt

fig = ppt.figure()
width = 0.36
ax = fig.add_axes([0,0,1.1,1])
label = ['Logistic recursion', 'Recursive Tree']
percentage = [result_1, result]
ax.bar(label, percentage)
ppt.show()

dlab

features = ['class','cap-shape','cap-surface','cap-color','bruises','odor','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']

x = dlab[features]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify = y, random_state=0,)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(x_train)

x_train_scaled = scaler.transform(x_train)
x_test_scaled = scaler.transform(x_test)

print("per-features minimum :\n {}".format(x_train_scaled.min(axis=0)))
print("per-features maximum :\n {}".format(x_train_scaled.max(axis=0)))